{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45effa2b",
   "metadata": {},
   "source": [
    "# Objective of This Part: Dataset Merging for Enriched Fraud Detection\n",
    "In this part of the exercise, the goal is to merge two datasets to create a more enriched and informative dataset for fraud detection. By combining transactional data (e.g., from fraudTrain.csv) with additional information (such as user profiles, merchant details, or geographic risk indicators), we aim to provide the model with more context that may help it better distinguish between fraudulent and legitimate transactions.\n",
    "\n",
    "This step involves:\n",
    "\n",
    "* Identifying common keys between datasets (e.g., user, cc_num, or merchant),\n",
    "\n",
    "* Ensuring structural compatibility (matching granularity, time periods, and data formats),\n",
    "\n",
    "* Performing a safe and meaningful join,\n",
    "\n",
    "* Validating the completeness and integrity of the merged result.\n",
    "\n",
    "Merging datasets properly can reveal hidden patterns, enhance feature richness, and ultimately boost model performance in identifying fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c50471",
   "metadata": {},
   "source": [
    "# Logigramme ‚Äì Fusion de deux datasets\n",
    "\n",
    "D√©but  \n",
    "  ‚îÇ  \n",
    "  ‚ñº  \n",
    "1. Identifier la cl√© de jointure  \n",
    "(ex : `user`, `cc_num`, `merchant`, etc.)  \n",
    "  ‚îÇ  \n",
    "  ‚ñº  \n",
    "2. V√©rifier la qualit√© de la cl√©  \n",
    "- Doublons ?  \n",
    "- Types compatibles ?  \n",
    "- Cl√©s correspondantes ?  \n",
    "  ‚îÇ  \n",
    "  ‚ñº  \n",
    "3. Fusionner les datasets  \n",
    "`pd.merge(df1, df2, how='left', on='cl√©')`  \n",
    "  ‚îÇ  \n",
    "  ‚ñº  \n",
    "4. Nettoyer le r√©sultat  \n",
    "- G√©rer les `NaN`  \n",
    "- Supprimer doublons  \n",
    "- V√©rifier dimensions  \n",
    "  ‚îÇ  \n",
    "  ‚ñº  \n",
    "5. Analyse exploratoire des nouvelles colonnes  \n",
    "- Statistiques  \n",
    "- Visualisations  \n",
    "- Corr√©lations  \n",
    "  ‚îÇ  \n",
    "  ‚ñº  \n",
    "Fin ‚Äì Dataset enrichi pr√™t pour la mod√©lisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fa0fba",
   "metadata": {},
   "source": [
    "## Premi√®re √©tape d‚Äôun merge entre deux datasets :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410340b6",
   "metadata": {},
   "source": [
    "a. Inspecter les colonnes de chaque dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc76c056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Chargement des fichiers CSV\n",
    "df1 = pd.read_csv(\"creditcard_dataset1.csv\")\n",
    "df2 = pd.read_csv(\"fraudTrain_dataset2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae000a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 columns: ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class']\n",
      "df2 columns: ['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'category', 'amt', 'first', 'last', 'gender', 'street', 'city', 'state', 'zip', 'lat', 'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time', 'merch_lat', 'merch_long', 'is_fraud']\n"
     ]
    }
   ],
   "source": [
    "# Affichage des colonnes\n",
    "print(\"df1 columns:\", df1.columns.tolist())\n",
    "print(\"df2 columns:\", df2.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0786151f",
   "metadata": {},
   "source": [
    " b. Chercher une ou plusieurs colonnes communes/logiques :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43770bd",
   "metadata": {},
   "source": [
    "Objectif de cette √©tape :\n",
    "‚û°Ô∏è Identifier une cl√© de correspondance fiable entre les deux datasets.\n",
    "Sans √ßa, aucune jointure n‚Äôa de sens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78919c4",
   "metadata": {},
   "source": [
    "| `df1`                            | `df2`       | üí¨ Remarques                                       |\n",
    "| -------------------------------- | ----------- | -------------------------------------------------- |\n",
    "| `Time`                           | `unix_time` | m√™me logique temporelle (√† confirmer avec un test) |\n",
    "| `Amount`                         | `amt`       | m√™me donn√©e, noms diff√©rents                       |\n",
    "| `Class`                          | `is_fraud`  | m√™me signification (√©tiquette binaire de fraude)   |\n",
    "| *(aucune autre colonne directe)* | `cc_num`    | **cl√© candidate** pour le `merge`                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ee46e6",
   "metadata": {},
   "source": [
    "C‚Äôest la seule vraie colonne d‚Äôidentifiant pr√©sente dans les deux datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21f7617",
   "metadata": {},
   "source": [
    " V√©rification recommand√©e avant merge :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9796b017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283871\n",
      "1295692\n"
     ]
    }
   ],
   "source": [
    "df1['cc_num'] = df2['cc_num']  # seulement si tu confirmes qu‚Äôils correspondent 1:1\n",
    "print(df1['cc_num'].duplicated().sum())  # doit √™tre 0\n",
    "print(df2['cc_num'].duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c692c752",
   "metadata": {},
   "source": [
    " Option 1 : Cl√© composite cc_num + Time\n",
    "df1 contient cc_num et Time (ou unix_time)\n",
    "\n",
    "df2 contient cc_num et unix_time\n",
    "\n",
    "Teste cette correspondance :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bda5530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 54)\n"
     ]
    }
   ],
   "source": [
    "df1['unix_time'] = df1['Time'].astype(int)  # si Time est exprim√© en secondes\n",
    "merged = pd.merge(df1, df2, how='inner', on=['cc_num', 'unix_time'])\n",
    "print(merged.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff3fe8",
   "metadata": {},
   "source": [
    "Il n‚Äôy a aucune combinaison exacte (cc_num, unix_time) commune aux deux datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bdcc59",
   "metadata": {},
   "source": [
    "Solution r√©aliste : ajuster les donn√©es pour cr√©er une cl√© de jointure approximative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6150c432",
   "metadata": {},
   "source": [
    "Option efficace : arrondir Time dans df1 pour se rapprocher de unix_time dans df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43d9dabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['approx_unix_time'] = df1['Time'].astype(int) + df2['unix_time'].min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1b72c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 58)\n"
     ]
    }
   ],
   "source": [
    "df1['key'] = df1['cc_num'].astype(str) + \"_\" + df1['approx_unix_time'].astype(str)\n",
    "df2['key'] = df2['cc_num'].astype(str) + \"_\" + df2['unix_time'].astype(str)\n",
    "\n",
    "df_merged = pd.merge(df1, df2, how='inner', on='key')\n",
    "print(df_merged.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b366c7",
   "metadata": {},
   "source": [
    "Parfait, (10, 58) signifie que la cl√© composite cc_num + unix_time a permis de trouver 10 correspondances exactes entre df1 et df2.\n",
    "\n",
    "Conclusion :\n",
    "* approche fonctionne\n",
    "* nous avons maintenant un dataset enrichi de 10 lignes pr√™tes pour exploration ou mod√©lisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f92b738",
   "metadata": {},
   "source": [
    "1. V√©rifier la qualit√© des donn√©es fusionn√©es :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a626efcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 58 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Time                   10 non-null     float64\n",
      " 1   V1                     10 non-null     float64\n",
      " 2   V2                     10 non-null     float64\n",
      " 3   V3                     10 non-null     float64\n",
      " 4   V4                     10 non-null     float64\n",
      " 5   V5                     10 non-null     float64\n",
      " 6   V6                     10 non-null     float64\n",
      " 7   V7                     10 non-null     float64\n",
      " 8   V8                     10 non-null     float64\n",
      " 9   V9                     10 non-null     float64\n",
      " 10  V10                    10 non-null     float64\n",
      " 11  V11                    10 non-null     float64\n",
      " 12  V12                    10 non-null     float64\n",
      " 13  V13                    10 non-null     float64\n",
      " 14  V14                    10 non-null     float64\n",
      " 15  V15                    10 non-null     float64\n",
      " 16  V16                    10 non-null     float64\n",
      " 17  V17                    10 non-null     float64\n",
      " 18  V18                    10 non-null     float64\n",
      " 19  V19                    10 non-null     float64\n",
      " 20  V20                    10 non-null     float64\n",
      " 21  V21                    10 non-null     float64\n",
      " 22  V22                    10 non-null     float64\n",
      " 23  V23                    10 non-null     float64\n",
      " 24  V24                    10 non-null     float64\n",
      " 25  V25                    10 non-null     float64\n",
      " 26  V26                    10 non-null     float64\n",
      " 27  V27                    10 non-null     float64\n",
      " 28  V28                    10 non-null     float64\n",
      " 29  Amount                 10 non-null     float64\n",
      " 30  Class                  10 non-null     int64  \n",
      " 31  cc_num_x               10 non-null     int64  \n",
      " 32  unix_time_x            10 non-null     int64  \n",
      " 33  approx_unix_time       10 non-null     int64  \n",
      " 34  key                    10 non-null     object \n",
      " 35  Unnamed: 0             10 non-null     int64  \n",
      " 36  trans_date_trans_time  10 non-null     object \n",
      " 37  cc_num_y               10 non-null     int64  \n",
      " 38  merchant               10 non-null     object \n",
      " 39  category               10 non-null     object \n",
      " 40  amt                    10 non-null     float64\n",
      " 41  first                  10 non-null     object \n",
      " 42  last                   10 non-null     object \n",
      " 43  gender                 10 non-null     object \n",
      " 44  street                 10 non-null     object \n",
      " 45  city                   10 non-null     object \n",
      " 46  state                  10 non-null     object \n",
      " 47  zip                    10 non-null     int64  \n",
      " 48  lat                    10 non-null     float64\n",
      " 49  long                   10 non-null     float64\n",
      " 50  city_pop               10 non-null     int64  \n",
      " 51  job                    10 non-null     object \n",
      " 52  dob                    10 non-null     object \n",
      " 53  trans_num              10 non-null     object \n",
      " 54  unix_time_y            10 non-null     int64  \n",
      " 55  merch_lat              10 non-null     float64\n",
      " 56  merch_long             10 non-null     float64\n",
      " 57  is_fraud               10 non-null     int64  \n",
      "dtypes: float64(35), int64(10), object(13)\n",
      "memory usage: 4.7+ KB\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "5c894942-4997-4829-a53e-9c990c0fd683",
       "rows": [
        [
         "Time",
         "0"
        ],
        [
         "V1",
         "0"
        ],
        [
         "V2",
         "0"
        ],
        [
         "V3",
         "0"
        ],
        [
         "V4",
         "0"
        ],
        [
         "V5",
         "0"
        ],
        [
         "V6",
         "0"
        ],
        [
         "V7",
         "0"
        ],
        [
         "V8",
         "0"
        ],
        [
         "V9",
         "0"
        ],
        [
         "V10",
         "0"
        ],
        [
         "V11",
         "0"
        ],
        [
         "V12",
         "0"
        ],
        [
         "V13",
         "0"
        ],
        [
         "V14",
         "0"
        ],
        [
         "V15",
         "0"
        ],
        [
         "V16",
         "0"
        ],
        [
         "V17",
         "0"
        ],
        [
         "V18",
         "0"
        ],
        [
         "V19",
         "0"
        ],
        [
         "V20",
         "0"
        ],
        [
         "V21",
         "0"
        ],
        [
         "V22",
         "0"
        ],
        [
         "V23",
         "0"
        ],
        [
         "V24",
         "0"
        ],
        [
         "V25",
         "0"
        ],
        [
         "V26",
         "0"
        ],
        [
         "V27",
         "0"
        ],
        [
         "V28",
         "0"
        ],
        [
         "Amount",
         "0"
        ],
        [
         "Class",
         "0"
        ],
        [
         "cc_num_x",
         "0"
        ],
        [
         "unix_time_x",
         "0"
        ],
        [
         "approx_unix_time",
         "0"
        ],
        [
         "key",
         "0"
        ],
        [
         "Unnamed: 0",
         "0"
        ],
        [
         "trans_date_trans_time",
         "0"
        ],
        [
         "cc_num_y",
         "0"
        ],
        [
         "merchant",
         "0"
        ],
        [
         "category",
         "0"
        ],
        [
         "amt",
         "0"
        ],
        [
         "first",
         "0"
        ],
        [
         "last",
         "0"
        ],
        [
         "gender",
         "0"
        ],
        [
         "street",
         "0"
        ],
        [
         "city",
         "0"
        ],
        [
         "state",
         "0"
        ],
        [
         "zip",
         "0"
        ],
        [
         "lat",
         "0"
        ],
        [
         "long",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 58
       }
      },
      "text/plain": [
       "Time                     0\n",
       "V1                       0\n",
       "V2                       0\n",
       "V3                       0\n",
       "V4                       0\n",
       "V5                       0\n",
       "V6                       0\n",
       "V7                       0\n",
       "V8                       0\n",
       "V9                       0\n",
       "V10                      0\n",
       "V11                      0\n",
       "V12                      0\n",
       "V13                      0\n",
       "V14                      0\n",
       "V15                      0\n",
       "V16                      0\n",
       "V17                      0\n",
       "V18                      0\n",
       "V19                      0\n",
       "V20                      0\n",
       "V21                      0\n",
       "V22                      0\n",
       "V23                      0\n",
       "V24                      0\n",
       "V25                      0\n",
       "V26                      0\n",
       "V27                      0\n",
       "V28                      0\n",
       "Amount                   0\n",
       "Class                    0\n",
       "cc_num_x                 0\n",
       "unix_time_x              0\n",
       "approx_unix_time         0\n",
       "key                      0\n",
       "Unnamed: 0               0\n",
       "trans_date_trans_time    0\n",
       "cc_num_y                 0\n",
       "merchant                 0\n",
       "category                 0\n",
       "amt                      0\n",
       "first                    0\n",
       "last                     0\n",
       "gender                   0\n",
       "street                   0\n",
       "city                     0\n",
       "state                    0\n",
       "zip                      0\n",
       "lat                      0\n",
       "long                     0\n",
       "city_pop                 0\n",
       "job                      0\n",
       "dob                      0\n",
       "trans_num                0\n",
       "unix_time_y              0\n",
       "merch_lat                0\n",
       "merch_long               0\n",
       "is_fraud                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.info()\n",
    "df_merged.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bc669d",
   "metadata": {},
   "source": [
    "Parfait, tu disposes maintenant d‚Äôun dataset enrichi avec :\n",
    "\n",
    "‚úÖ les variables anonymis√©es (V1‚ÄìV28), Amount, Class\n",
    "\n",
    "‚úÖ les m√©tadonn√©es r√©elles : merchant, category, cc_num, dob, job, is_fraud, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97d1695",
   "metadata": {},
   "source": [
    "1. Nettoyage des colonnes redondantes\n",
    "Tu as des doublons :\n",
    "\n",
    "cc_num_x / cc_num_y\n",
    "\n",
    "amt / Amount\n",
    "\n",
    "unix_time_x, unix_time_y, approx_unix_time\n",
    "\n",
    "Class / is_fraud\n",
    "\n",
    "üîß Garde uniquement les colonnes utiles et unifie :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d8409a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_merged.copy()\n",
    "\n",
    "df_cleaned = df_cleaned.drop(columns=[\n",
    "    'cc_num_y', 'amt', 'unix_time_x', 'unix_time_y',\n",
    "    'approx_unix_time', 'Amount', 'Class'  # on garde 'is_fraud'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d0cc5b",
   "metadata": {},
   "source": [
    "2. Normalisation des types et formatage des dates :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06e57ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['trans_date_trans_time'] = pd.to_datetime(df_cleaned['trans_date_trans_time'])\n",
    "df_cleaned['dob'] = pd.to_datetime(df_cleaned['dob'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febe18ec",
   "metadata": {},
   "source": [
    "3. Cr√©ation de variables utiles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1fcf2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['age'] = df_cleaned['trans_date_trans_time'].dt.year - df_cleaned['dob'].dt.year\n",
    "df_cleaned['hour'] = df_cleaned['trans_date_trans_time'].dt.hour\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eaae12",
   "metadata": {},
   "source": [
    "Etape : Encodage des variables cat√©gorielles pour mod√©lisation\n",
    "Tu as des colonnes object (texte) comme :\n",
    "\n",
    "merchant, category, gender, job, state, city, etc.\n",
    "\n",
    "√âtape : Encodage one-hot simplifi√© ou label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95cf84f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df_encoded = df_cleaned.copy()\n",
    "for col in ['gender', 'category', 'state']:\n",
    "    le = LabelEncoder()\n",
    "    df_encoded[col] = le.fit_transform(df_encoded[col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cba5de",
   "metadata": {},
   "source": [
    "**Raisons claires et argument√©es** pour continuer l'exercice avec le **`creditcard_dataset1`** (le dataset original issu de Kaggle) :\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ 1. **Volume suffisant pour apprentissage**\n",
    "\n",
    "* `creditcard_dataset1` contient **284‚ÄØ807 transactions**, dont **492 fraudes** (soit \\~0.17%).\n",
    "* C‚Äôest suffisant pour :\n",
    "\n",
    "  * entra√Æner des mod√®les robustes,\n",
    "  * effectuer un **split train/test fiable**,\n",
    "  * et appliquer des techniques d‚Äô√©quilibrage (ex. SMOTE).\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ 2. **Nettoy√© et pr√™t √† l‚Äôemploi**\n",
    "\n",
    "* Les colonnes sont **num√©riques** (V1‚ÄìV28, Amount, Time, Class).\n",
    "* Aucune donn√©e textuelle ni bruit inutile.\n",
    "* Id√©al pour PCA, RandomForest, XGBoost ou r√©seaux neuronaux.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ 3. **Align√© avec l'objectif du hackathon**\n",
    "\n",
    "* Le sujet impose : **fraude sur transactions de carte bancaire**.\n",
    "* Ce dataset simule exactement cela, avec anonymisation r√©aliste (PCA sur features).\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ 4. **Benchmark connu**\n",
    "\n",
    "* Il est utilis√© comme **r√©f√©rence dans la recherche et les publications**.\n",
    "* Tu pourras **comparer tes scores AUC, recall, etc.** avec d‚Äôautres solutions publi√©es.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ 5. **Adapt√© √† un cycle complet de mod√©lisation**\n",
    "\n",
    "* Tu peux y appliquer :\n",
    "\n",
    "  * **EDA**\n",
    "  * **Mod√©lisation supervis√©e**\n",
    "  * **Techniques d‚Äô√©chantillonnage**\n",
    "  * **√âvaluation stricte sur donn√©es d√©s√©quilibr√©es**\n",
    "  * Et m√™me cr√©er un **dashboard de suivi de fraude (PowerBI/Tableau)**\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Conclusion :\n",
    "\n",
    "Le dataset enrichi √©tait utile pour tester le **merge et l‚Äôenrichissement contextuel**,\n",
    "mais le `creditcard_dataset1` est **indispensable pour la mod√©lisation s√©rieuse**.\n",
    "\n",
    "Souhaites-tu qu‚Äôon reprenne directement un pipeline complet avec ce dataset ?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
